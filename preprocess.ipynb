{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir, remove, mkdir\n",
    "from os.path import join as join_path\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from pyonmttok import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing europarl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro_data_dir = \"../europarl/aligned/\"\n",
    "output_data_dir = \"./data/original/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for l_pair in listdir(euro_data_dir):\n",
    "    pair_path = join_path(euro_data_dir, l_pair)\n",
    "    for l_dir in listdir(pair_path):\n",
    "        out_file = open(output_data_dir + l_pair + \"_\" + l_dir + \".txt\", \"w\")\n",
    "        l_path = join_path(pair_path, l_dir)\n",
    "        for file_name in sorted(listdir(l_path)):\n",
    "            # Consume content and split lines\n",
    "            content = open(join_path(l_path, file_name), \"r\").read() \n",
    "\n",
    "            # Write content in output file\n",
    "            out_file.write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(data_dir, as_np_array=False):\n",
    "    corpus = {}\n",
    "    for file_name in listdir(data_dir):\n",
    "        path = join_path(data_dir, file_name)\n",
    "        if os.path.isfile(path):\n",
    "            file = open(path, \"r+\")\n",
    "            l_pair = file_name[:5]\n",
    "            if l_pair not in corpus:\n",
    "                corpus[l_pair] = {}\n",
    "            if as_np_array:\n",
    "                corpus[l_pair][file_name] = np.array(file.read().split('\\n'), dtype=object)\n",
    "            else:\n",
    "                corpus[l_pair][file_name[:3]] = file.read().split('\\n')\n",
    "            file.close()\n",
    "            remove(path)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_corpus(output_data_dir, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete short lines and lines with xml tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2000491\n2000491\n1910858\n1910858\n1958593\n1958593\n"
    }
   ],
   "source": [
    "for pair, l_data in corpus.items():\n",
    "\n",
    "    # Find special lines\n",
    "    empty_lines = np.array([], dtype=int)\n",
    "    for _, value in l_data.items():\n",
    "        is_empty = np.vectorize(lambda x: len(x) <= 7 or x[0] == \"<\" or x[0] == \"(\")\n",
    "        indices = np.nonzero(is_empty(value))[0]\n",
    "        empty_lines = np.concatenate((empty_lines, indices))\n",
    "    empty_lines = np.unique(empty_lines)\n",
    "\n",
    "    # Remove lines with an xml tag or an empty char\n",
    "    for key, value in l_data.items():\n",
    "        new_corpus = np.delete(value, empty_lines)\n",
    "        corpus[pair][key] = new_corpus.tolist()\n",
    "        print(len(new_corpus))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_pair, pair_dict in corpus.items():\n",
    "    for file_name, data in pair_dict.items():\n",
    "        file = open(join_path(output_data_dir, file_name), 'w')\n",
    "        file.write(\"\\n\".join(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following steps must be run after executing the multialign script and the BPE tokenization script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join language files and add translation token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dir = './data/tokenized/'\n",
    "output_dir = './data/'\n",
    "\n",
    "for sub_set in listdir(tokenized_dir):\n",
    "    sub_set_path = join_path(tokenized_dir, sub_set)\n",
    "\n",
    "    corpus = {}\n",
    "    src_data = []\n",
    "    tgt_data = []\n",
    "\n",
    "    for file_name in listdir(sub_set_path):\n",
    "        file_path = join_path(sub_set_path, file_name)\n",
    "        file = open(file_path, 'r')\n",
    "        corpus[file_name[:-4]] = file.read().split('\\n')\n",
    "\n",
    "    # An extra line will be created when loading the data to memory,\n",
    "    # that's why the -1 is there\n",
    "    for i in range(0, len(corpus['en']) - 1):\n",
    "        for src in corpus:\n",
    "            targets = filter(lambda x: x != src, corpus.keys())\n",
    "            for tgt in targets:\n",
    "                src_sentence = '_src_{}_tgt_{} '.format(src, tgt) + corpus[src][i]\n",
    "                src_data.append(src_sentence)\n",
    "                tgt_data.append(corpus[tgt][i])\n",
    "\n",
    "    out_src = open(join_path(output_dir, 'europarl_{}_src.txt'.format(sub_set)), 'w')\n",
    "    out_src.write(\"\\n\".join(src_data))\n",
    "    out_src = open(join_path(output_dir, 'europarl_{}_tgt.txt'.format(sub_set)), 'w')\n",
    "    out_src.write(\"\\n\".join(tgt_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing classifier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = './data/translated/'\n",
    "out_location = './data/'\n",
    "lang_pool = ['en', 'es', 'fr', 'de']\n",
    "back_translation_num = 3\n",
    "file_size = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Back-Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting loops for: fr_es.txt\nElapsed time to generate T0 for es to en: 72.79625606536865s\nElapsed time to generate Back0 for en to es: 71.71730089187622s\nElapsed time to generate T1 for es to en: 67.70391917228699s\nElapsed time to generate Back1 for en to es: 69.71693444252014s\nElapsed time to generate T2 for es to en: 66.12536144256592s\nElapsed time to generate Back2 for en to es: 69.00499105453491s\nElapsed time to generate T3 for es to en: 66.20717287063599s\nElapsed time to generate T0 for es to fr: 83.52035069465637s\nElapsed time to generate Back0 for fr to es: 72.34266018867493s\nElapsed time to generate T1 for es to fr: 75.88401317596436s\nElapsed time to generate Back1 for fr to es: 68.62711930274963s\nElapsed time to generate T2 for es to fr: 74.03134655952454s\nElapsed time to generate Back2 for fr to es: 68.49460077285767s\nElapsed time to generate T3 for es to fr: 73.70856547355652s\nElapsed time to generate T0 for es to de: 75.48436570167542s\nElapsed time to generate Back0 for de to es: 71.38216710090637s\nElapsed time to generate T1 for es to de: 68.45099711418152s\nElapsed time to generate Back1 for de to es: 68.15904092788696s\nElapsed time to generate T2 for es to de: 66.57942414283752s\nElapsed time to generate Back2 for de to es: 66.6779477596283s\nElapsed time to generate T3 for es to de: 66.37067556381226s\nStarting loops for: fr_de.txt\nElapsed time to generate T0 for de to en: 74.02451848983765s\nElapsed time to generate Back0 for en to de: 71.30349612236023s\nElapsed time to generate T1 for de to en: 67.53146314620972s\nElapsed time to generate Back1 for en to de: 68.06285095214844s\nElapsed time to generate T2 for de to en: 65.30203151702881s\nElapsed time to generate Back2 for en to de: 66.3643045425415s\nElapsed time to generate T3 for de to en: 63.76413369178772s\nElapsed time to generate T0 for de to es: 77.30409860610962s\nElapsed time to generate Back0 for es to de: 69.78660702705383s\nElapsed time to generate T1 for de to es: 69.42180013656616s\nElapsed time to generate Back1 for es to de: 66.47912883758545s\nElapsed time to generate T2 for de to es: 67.25517964363098s\nElapsed time to generate Back2 for es to de: 65.48180413246155s\nElapsed time to generate T3 for de to es: 66.65433144569397s\nElapsed time to generate T0 for de to fr: 84.01940655708313s\nElapsed time to generate Back0 for fr to de: 69.87639617919922s\nElapsed time to generate T1 for de to fr: 74.36627125740051s\nElapsed time to generate Back1 for fr to de: 66.54151582717896s\nElapsed time to generate T2 for de to fr: 72.2009813785553s\nElapsed time to generate Back2 for fr to de: 65.36383175849915s\nElapsed time to generate T3 for de to fr: 71.1572003364563s\nStarting loops for: es_fr.txt\nElapsed time to generate T0 for fr to en: 75.0135726928711s\nElapsed time to generate Back0 for en to fr: 79.77263593673706s\nElapsed time to generate T1 for fr to en: 69.40851736068726s\nElapsed time to generate Back1 for en to fr: 75.3788845539093s\nElapsed time to generate T2 for fr to en: 66.10029649734497s\nElapsed time to generate Back2 for en to fr: 74.26281714439392s\nElapsed time to generate T3 for fr to en: 65.01387596130371s\nElapsed time to generate T0 for fr to es: 76.44830346107483s\nElapsed time to generate Back0 for es to fr: 77.41766309738159s\nElapsed time to generate T1 for fr to es: 70.43980717658997s\nElapsed time to generate Back1 for es to fr: 75.32253909111023s\nElapsed time to generate T2 for fr to es: 69.13027501106262s\nElapsed time to generate Back2 for es to fr: 74.10446643829346s\nElapsed time to generate T3 for fr to es: 67.89234209060669s\nElapsed time to generate T0 for fr to de: 76.86114144325256s\nElapsed time to generate Back0 for de to fr: 76.8155906200409s\nElapsed time to generate T1 for fr to de: 67.54813551902771s\nElapsed time to generate Back1 for de to fr: 72.50167465209961s\nElapsed time to generate T2 for fr to de: 65.72718787193298s\nElapsed time to generate Back2 for de to fr: 71.86294317245483s\nElapsed time to generate T3 for fr to de: 65.8347840309143s\nStarting loops for: de_en.txt\nElapsed time to generate T0 for en to es: 88.64368391036987s\nElapsed time to generate Back0 for es to en: 70.98667311668396s\nElapsed time to generate T1 for en to es: 72.47119450569153s\nElapsed time to generate Back1 for es to en: 68.33445954322815s\nElapsed time to generate T2 for en to es: 71.82185292243958s\nElapsed time to generate Back2 for es to en: 67.25885248184204s\nElapsed time to generate T3 for en to es: 69.88807320594788s\nElapsed time to generate T0 for en to fr: 94.18982672691345s\nElapsed time to generate Back0 for fr to en: 71.2052686214447s\nElapsed time to generate T1 for en to fr: 77.19172835350037s\nElapsed time to generate Back1 for fr to en: 65.45754671096802s\nElapsed time to generate T2 for en to fr: 73.22876739501953s\nElapsed time to generate Back2 for fr to en: 65.91492342948914s\nElapsed time to generate T3 for en to fr: 73.00559592247009s\nElapsed time to generate T0 for en to de: 87.24823141098022s\nElapsed time to generate Back0 for de to en: 69.06344485282898s\nElapsed time to generate T1 for en to de: 66.52642059326172s\nElapsed time to generate Back1 for de to en: 62.80466055870056s\nElapsed time to generate T2 for en to de: 63.70229506492615s\nElapsed time to generate Back2 for de to en: 62.28820276260376s\nElapsed time to generate T3 for en to de: 65.12294483184814s\nStarting loops for: fr_en.txt\nElapsed time to generate T0 for en to es: 78.51184153556824s\nElapsed time to generate Back0 for es to en: 69.69005990028381s\nElapsed time to generate T1 for en to es: 70.68528342247009s\nElapsed time to generate Back1 for es to en: 66.90681600570679s\nElapsed time to generate T2 for en to es: 69.40993928909302s\nElapsed time to generate Back2 for es to en: 66.1841983795166s\nElapsed time to generate T3 for en to es: 69.00315308570862s\nElapsed time to generate T0 for en to fr: 85.79281783103943s\nElapsed time to generate Back0 for fr to en: 70.48878121376038s\nElapsed time to generate T1 for en to fr: 76.41938638687134s\nElapsed time to generate Back1 for fr to en: 67.32258558273315s\nElapsed time to generate T2 for en to fr: 75.26605892181396s\nElapsed time to generate Back2 for fr to en: 67.28445291519165s\nElapsed time to generate T3 for en to fr: 74.83198857307434s\nElapsed time to generate T0 for en to de: 77.32542634010315s\nElapsed time to generate Back0 for de to en: 68.39960145950317s\nElapsed time to generate T1 for en to de: 68.16729640960693s\nElapsed time to generate Back1 for de to en: 66.60804510116577s\nElapsed time to generate T2 for en to de: 68.23641467094421s\nElapsed time to generate Back2 for de to en: 65.64529967308044s\nElapsed time to generate T3 for en to de: 66.84700536727905s\nStarting loops for: de_es.txt\nElapsed time to generate T0 for es to en: 83.04584741592407s\nElapsed time to generate Back0 for en to es: 73.34414887428284s\nElapsed time to generate T1 for es to en: 66.16602826118469s\nElapsed time to generate Back1 for en to es: 68.98847484588623s\nElapsed time to generate T2 for es to en: 66.72944045066833s\nElapsed time to generate Back2 for en to es: 69.05427598953247s\nElapsed time to generate T3 for es to en: 64.46766257286072s\nElapsed time to generate T0 for es to fr: 92.72370028495789s\nElapsed time to generate Back0 for fr to es: 72.93671107292175s\nElapsed time to generate T1 for es to fr: 76.68030071258545s\nElapsed time to generate Back1 for fr to es: 71.11825847625732s\nElapsed time to generate T2 for es to fr: 79.9064371585846s\nElapsed time to generate Back2 for fr to es: 74.11840081214905s\nElapsed time to generate T3 for es to fr: 79.16656517982483s\nElapsed time to generate T0 for es to de: 85.37273955345154s\nElapsed time to generate Back0 for de to es: 70.64256143569946s\nElapsed time to generate T1 for es to de: 66.89848971366882s\nElapsed time to generate Back1 for de to es: 66.55208373069763s\nElapsed time to generate T2 for es to de: 64.6535997390747s\nElapsed time to generate Back2 for de to es: 63.22974228858948s\nElapsed time to generate T3 for es to de: 62.37768530845642s\nStarting loops for: es_en.txt\nElapsed time to generate T0 for en to es: 77.67711019515991s\nElapsed time to generate Back0 for es to en: 68.57044672966003s\nElapsed time to generate T1 for en to es: 70.49407649040222s\nElapsed time to generate Back1 for es to en: 67.05415058135986s\nElapsed time to generate T2 for en to es: 69.18728041648865s\nElapsed time to generate Back2 for es to en: 66.34449791908264s\nElapsed time to generate T3 for en to es: 69.33316588401794s\nElapsed time to generate T0 for en to fr: 84.729651927948s\nElapsed time to generate Back0 for fr to en: 69.0516369342804s\nElapsed time to generate T1 for en to fr: 75.83002281188965s\nElapsed time to generate Back1 for fr to en: 65.923748254776s\nElapsed time to generate T2 for en to fr: 74.01891207695007s\nElapsed time to generate Back2 for fr to en: 65.1657485961914s\nElapsed time to generate T3 for en to fr: 73.40787100791931s\nElapsed time to generate T0 for en to de: 76.85825157165527s\nElapsed time to generate Back0 for de to en: 69.21423363685608s\nElapsed time to generate T1 for en to de: 67.94569635391235s\nElapsed time to generate Back1 for de to en: 65.51886248588562s\nElapsed time to generate T2 for en to de: 67.08791494369507s\nElapsed time to generate Back2 for de to en: 66.28135848045349s\nElapsed time to generate T3 for en to de: 67.21032118797302s\nStarting loops for: en_es.txt\nElapsed time to generate T0 for es to en: 74.38454341888428s\nElapsed time to generate Back0 for en to es: 72.55975151062012s\nElapsed time to generate T1 for es to en: 67.04035663604736s\nElapsed time to generate Back1 for en to es: 69.60179591178894s\nElapsed time to generate T2 for es to en: 65.84823727607727s\nElapsed time to generate Back2 for en to es: 68.95630049705505s\nElapsed time to generate T3 for es to en: 65.54329633712769s\nElapsed time to generate T0 for es to fr: 85.44481253623962s\nElapsed time to generate Back0 for fr to es: 72.40393114089966s\nElapsed time to generate T1 for es to fr: 76.14873480796814s\nElapsed time to generate Back1 for fr to es: 68.55406641960144s\nElapsed time to generate T2 for es to fr: 74.52043223381042s\nElapsed time to generate Back2 for fr to es: 67.90102577209473s\nElapsed time to generate T3 for es to fr: 73.64781546592712s\nElapsed time to generate T0 for es to de: 77.45106887817383s\nElapsed time to generate Back0 for de to es: 71.54727721214294s\nElapsed time to generate T1 for es to de: 68.35907983779907s\nElapsed time to generate Back1 for de to es: 68.00795078277588s\nElapsed time to generate T2 for es to de: 67.25238847732544s\nElapsed time to generate Back2 for de to es: 67.09089469909668s\nElapsed time to generate T3 for es to de: 66.50644111633301s\nStarting loops for: es_de.txt\nElapsed time to generate T0 for de to en: 78.36355972290039s\nElapsed time to generate Back0 for en to de: 70.77821922302246s\nElapsed time to generate T1 for de to en: 66.18150067329407s\nElapsed time to generate Back1 for en to de: 67.52600908279419s\nElapsed time to generate T2 for de to en: 65.49621677398682s\nElapsed time to generate Back2 for en to de: 66.93734669685364s\nElapsed time to generate T3 for de to en: 64.58173322677612s\nElapsed time to generate T0 for de to es: 80.31932497024536s\nElapsed time to generate Back0 for es to de: 70.23521280288696s\nElapsed time to generate T1 for de to es: 68.0231831073761s\nElapsed time to generate Back1 for es to de: 65.20081400871277s\nElapsed time to generate T2 for de to es: 66.02584028244019s\nElapsed time to generate Back2 for es to de: 64.82090425491333s\nElapsed time to generate T3 for de to es: 66.37977600097656s\nElapsed time to generate T0 for de to fr: 86.3340573310852s\nElapsed time to generate Back0 for fr to de: 71.75364375114441s\nElapsed time to generate T1 for de to fr: 73.95609855651855s\nElapsed time to generate Back1 for fr to de: 66.52701473236084s\nElapsed time to generate T2 for de to fr: 71.23303699493408s\nElapsed time to generate Back2 for fr to de: 65.15136504173279s\nElapsed time to generate T3 for de to fr: 70.60110306739807s\nStarting loops for: en_de.txt\nElapsed time to generate T0 for de to en: 73.24771404266357s\nElapsed time to generate Back0 for en to de: 71.23160457611084s\nElapsed time to generate T1 for de to en: 67.14219212532043s\nElapsed time to generate Back1 for en to de: 66.73568034172058s\nElapsed time to generate T2 for de to en: 64.40382194519043s\nElapsed time to generate Back2 for en to de: 65.79791712760925s\nElapsed time to generate T3 for de to en: 64.56312251091003s\nElapsed time to generate T0 for de to es: 76.0516517162323s\nElapsed time to generate Back0 for es to de: 69.32869911193848s\nElapsed time to generate T1 for de to es: 69.14087915420532s\nElapsed time to generate Back1 for es to de: 66.94892358779907s\nElapsed time to generate T2 for de to es: 67.29186916351318s\nElapsed time to generate Back2 for es to de: 65.1277015209198s\nElapsed time to generate T3 for de to es: 66.63767790794373s\nElapsed time to generate T0 for de to fr: 85.23025012016296s\nElapsed time to generate Back0 for fr to de: 70.34893560409546s\nElapsed time to generate T1 for de to fr: 74.38874077796936s\nElapsed time to generate Back1 for fr to de: 66.01648473739624s\nElapsed time to generate T2 for de to fr: 72.80428504943848s\nElapsed time to generate Back2 for fr to de: 66.3573579788208s\nElapsed time to generate T3 for de to fr: 72.55240654945374s\nStarting loops for: de_fr.txt\nElapsed time to generate T0 for fr to en: 72.98590898513794s\nElapsed time to generate Back0 for en to fr: 78.09334588050842s\nElapsed time to generate T1 for fr to en: 66.30129671096802s\nElapsed time to generate Back1 for en to fr: 75.7649884223938s\nElapsed time to generate T2 for fr to en: 64.9764609336853s\nElapsed time to generate Back2 for en to fr: 72.79492282867432s\nElapsed time to generate T3 for fr to en: 63.99085521697998s\nElapsed time to generate T0 for fr to es: 75.68557357788086s\nElapsed time to generate Back0 for es to fr: 76.33883237838745s\nElapsed time to generate T1 for fr to es: 69.20631408691406s\nElapsed time to generate Back1 for es to fr: 75.066241979599s\nElapsed time to generate T2 for fr to es: 69.92912673950195s\nElapsed time to generate Back2 for es to fr: 76.00955510139465s\nElapsed time to generate T3 for fr to es: 68.78382802009583s\nElapsed time to generate T0 for fr to de: 76.01955771446228s\nElapsed time to generate Back0 for de to fr: 76.966228723526s\nElapsed time to generate T1 for fr to de: 67.13963031768799s\nElapsed time to generate Back1 for de to fr: 71.98986673355103s\nElapsed time to generate T2 for fr to de: 66.34887623786926s\nElapsed time to generate Back2 for de to fr: 72.51047110557556s\nElapsed time to generate T3 for fr to de: 65.83539271354675s\nStarting loops for: en_fr.txt\nElapsed time to generate T0 for fr to en: 75.84665012359619s\nElapsed time to generate Back0 for en to fr: 79.33807468414307s\nElapsed time to generate T1 for fr to en: 67.0317153930664s\nElapsed time to generate Back1 for en to fr: 74.85652947425842s\nElapsed time to generate T2 for fr to en: 66.00768637657166s\nElapsed time to generate Back2 for en to fr: 75.09392547607422s\nElapsed time to generate T3 for fr to en: 65.92338442802429s\nElapsed time to generate T0 for fr to es: 78.57051634788513s\nElapsed time to generate Back0 for es to fr: 76.61776351928711s\nElapsed time to generate T1 for fr to es: 69.29325675964355s\nElapsed time to generate Back1 for es to fr: 75.87454438209534s\nElapsed time to generate T2 for fr to es: 70.01576018333435s\nElapsed time to generate Back2 for es to fr: 76.13402318954468s\nElapsed time to generate T3 for fr to es: 69.51193165779114s\nElapsed time to generate T0 for fr to de: 77.34522604942322s\nElapsed time to generate Back0 for de to fr: 77.22590446472168s\nElapsed time to generate T1 for fr to de: 67.96438193321228s\nElapsed time to generate Back1 for de to fr: 72.99990916252136s\nElapsed time to generate T2 for fr to de: 67.10032296180725s\nElapsed time to generate Back2 for de to fr: 73.36730933189392s\nElapsed time to generate T3 for fr to de: 67.0472981929779s\n"
    }
   ],
   "source": [
    "ignore = []\n",
    "\n",
    "def translate_text(text, src, tgt, file_name, dir_path):\n",
    "    start = time.time()\n",
    "    response = requests.post('http://localhost:8080/translate', data = {'text': text, 'src': src, 'tgt': tgt})\n",
    "    end = time.time()\n",
    "    print('Elapsed time to generate {} for {} to {}: {}s'.format(file_name, src, tgt, end - start))\n",
    "    res_file = open(join_path(dir_path, '{}.txt'.format(file_name)), 'w')\n",
    "    res_file.write(response.text)\n",
    "    return response.text\n",
    "\n",
    "for file_name in listdir(location):\n",
    "    path = join_path(location, file_name)\n",
    "    dir_path = path[:-4]\n",
    "    if os.path.isfile(path) and file_name[:-4] not in ignore:\n",
    "        print(\"Starting loops for:\", file_name)\n",
    "        original_lang = file_name[:2]\n",
    "        translated_lang = file_name[-6:-4]\n",
    "\n",
    "        if not os.path.isdir(dir_path):\n",
    "            mkdir(dir_path)\n",
    "\n",
    "        content = open(path, 'r').read()\n",
    "        \n",
    "        for tgt in filter(lambda x: x != translated_lang, lang_pool):\n",
    "            tgt_dir = join_path(dir_path, tgt)\n",
    "            if not os.path.isdir(tgt_dir):\n",
    "                mkdir(tgt_dir)\n",
    "\n",
    "            last_back = content\n",
    "            for i in range(0, back_translation_num):\n",
    "                translation = translate_text(last_back, translated_lang, tgt, 'T{}'.format(i), tgt_dir)\n",
    "                last_back = translate_text(translation, tgt, translated_lang, 'Back{}'.format(i), tgt_dir)\n",
    "            translate_text(last_back, translated_lang, tgt, 'T{}'.format(back_translation_num), tgt_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate BLEU-Score Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['T{}-T{}_{}'.format(i, i+1, lang) for lang in lang_pool for i in range(\n",
    "    0, back_translation_num)] + ['src', 'origin', 'len']\n",
    "data = np.zeros((4*back_translation_num+3))\n",
    "tokenizer = Tokenizer('conservative')\n",
    "smoothing = SmoothingFunction()\n",
    "# score_func = lambda ref, hyp: sentence_bleu([ref], hyp, smoothing_function=smoothing.method4)\n",
    "score_func = lambda ref, hyp: meteor_score([ref], hyp)\n",
    "\n",
    "dirs = os.listdir(location)\n",
    "for directory in [d for d in os.listdir(location) if os.path.isdir(join_path(location, d))]:\n",
    "    path = join_path(location, directory)\n",
    "    bleu_data = np.zeros((file_size, 4*back_translation_num))\n",
    "\n",
    "    # Calculate BLEU Score for each sentence and its back-translations\n",
    "    for lang_idx, lang in enumerate(lang_pool):\n",
    "        lang_path = join_path(path, lang)\n",
    "        if not os.path.isdir(lang_path):\n",
    "            pass\n",
    "        else:\n",
    "            sentences = []\n",
    "            for i in range(0, back_translation_num + 1):\n",
    "                file_name = 'T{}.txt'.format(i)\n",
    "                file_data = open(join_path(lang_path, file_name),\n",
    "                                 'r').read().split('\\n')\n",
    "                sentences.append(file_data)\n",
    "\n",
    "            for i in range(0, len(sentences[0])):\n",
    "                for j in range(0, back_translation_num):\n",
    "                    # ref_sentence, _ = tokenizer.tokenize(sentences[j][i])\n",
    "                    # hypothesis, _ = tokenizer.tokenize(sentences[j+1][i])\n",
    "                    ref_sentence = sentences[j][i]\n",
    "                    hypothesis = sentences[j+1][i]\n",
    "                    bleu_data[i, lang_idx * back_translation_num +\n",
    "                        j] = score_func(ref_sentence, hypothesis) #if len(hypothesis) > 3 else 0\n",
    "\n",
    "    # Append src and origin data\n",
    "    bleu_data = np.hstack(\n",
    "        (bleu_data, np.full((file_size, 1), lang_pool.index(directory[-2:]))))\n",
    "    bleu_data = np.hstack(\n",
    "        (bleu_data, np.full((file_size, 1), lang_pool.index(directory[:2]))))\n",
    "\n",
    "    # Append sentence length data fron the src file\n",
    "    src_sentences = open(join_path(location, '{}.txt'.format(directory)), 'r').read().split('\\n')\n",
    "    tok_sentences = [tokenizer.tokenize(s)[0] for s in src_sentences]\n",
    "    lengths = [len(ts) for ts in tok_sentences]\n",
    "    bleu_data = np.hstack((bleu_data, np.array([lengths]).T))\n",
    "    \n",
    "    data = np.vstack((data, bleu_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.delete(data, (0), axis=0)\n",
    "dataFrame = pd.DataFrame(data, index=range(0, file_size*12), columns=columns)\n",
    "dataFrame['src'] = dataFrame['src'].apply(lambda x: lang_pool[int(x)])\n",
    "dataFrame['origin'] = dataFrame['origin'].apply(lambda x: lang_pool[int(x)])\n",
    "dataFrame.to_csv(join_path(out_location, 'meteor_table_200k.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   T0-T1_en  T1-T2_en  T2-T3_en  T0-T1_es  T1-T2_es  T2-T3_es  T0-T1_fr  \\\n0  0.997685  0.997685  0.997685  0.996000  0.996000  0.996000       0.0   \n1  0.780859  0.999624  0.999624  0.766154  0.920940  0.999772       0.0   \n2  0.998542  0.998542  0.998542  0.999023  0.999023  0.999023       0.0   \n3  0.916972  0.999500  0.999500  0.979938  0.999914  0.999914       0.0   \n4  0.500000  0.500000  0.500000  0.500000  0.500000  0.500000       0.0   \n\n   T1-T2_fr  T2-T3_fr  T0-T1_de  T1-T2_de  T2-T3_de src origin   len  \n0       0.0       0.0  0.996000  0.996000  0.996000  fr     en   8.0  \n1       0.0       0.0  0.921592  0.999624  0.999624  fr     en  17.0  \n2       0.0       0.0  0.999023  0.999023  0.999023  fr     en   9.0  \n3       0.0       0.0  0.928079  0.999711  0.999711  fr     en  15.0  \n4       0.0       0.0  0.500000  0.500000  0.500000  fr     en   1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>T0-T1_en</th>\n      <th>T1-T2_en</th>\n      <th>T2-T3_en</th>\n      <th>T0-T1_es</th>\n      <th>T1-T2_es</th>\n      <th>T2-T3_es</th>\n      <th>T0-T1_fr</th>\n      <th>T1-T2_fr</th>\n      <th>T2-T3_fr</th>\n      <th>T0-T1_de</th>\n      <th>T1-T2_de</th>\n      <th>T2-T3_de</th>\n      <th>src</th>\n      <th>origin</th>\n      <th>len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.997685</td>\n      <td>0.997685</td>\n      <td>0.997685</td>\n      <td>0.996000</td>\n      <td>0.996000</td>\n      <td>0.996000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.996000</td>\n      <td>0.996000</td>\n      <td>0.996000</td>\n      <td>fr</td>\n      <td>en</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.780859</td>\n      <td>0.999624</td>\n      <td>0.999624</td>\n      <td>0.766154</td>\n      <td>0.920940</td>\n      <td>0.999772</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.921592</td>\n      <td>0.999624</td>\n      <td>0.999624</td>\n      <td>fr</td>\n      <td>en</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.998542</td>\n      <td>0.998542</td>\n      <td>0.998542</td>\n      <td>0.999023</td>\n      <td>0.999023</td>\n      <td>0.999023</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.999023</td>\n      <td>0.999023</td>\n      <td>0.999023</td>\n      <td>fr</td>\n      <td>en</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.916972</td>\n      <td>0.999500</td>\n      <td>0.999500</td>\n      <td>0.979938</td>\n      <td>0.999914</td>\n      <td>0.999914</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.928079</td>\n      <td>0.999711</td>\n      <td>0.999711</td>\n      <td>fr</td>\n      <td>en</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>fr</td>\n      <td>en</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600487288067",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}