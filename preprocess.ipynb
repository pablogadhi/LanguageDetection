{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from os import listdir, remove, mkdir\n",
    "from os.path import join as join_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing europarl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "euro_data_dir = \"../europarl/aligned/\"\n",
    "output_data_dir = \"./data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for l_pair in listdir(euro_data_dir):\n",
    "    pair_path = join_path(euro_data_dir, l_pair)\n",
    "    for l_dir in listdir(pair_path):\n",
    "        out_file = open(output_data_dir + l_pair + \"_\" + l_dir + \".txt\", \"w\")\n",
    "        l_path = join_path(pair_path, l_dir)\n",
    "        for file_name in sorted(listdir(l_path)):\n",
    "            # Consume content and split lines\n",
    "            content = open(join_path(l_path, file_name), \"r\").read() \n",
    "\n",
    "            # Write content in output file\n",
    "            out_file.write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(data_dir, as_np_array=False):\n",
    "    corpus = {}\n",
    "    for file_name in listdir(data_dir):\n",
    "        path = join_path(data_dir, file_name)\n",
    "        if os.path.isfile(path):\n",
    "            file = open(path, \"r+\")\n",
    "            l_pair = file_name[:5]\n",
    "            if l_pair not in corpus:\n",
    "                corpus[l_pair] = {}\n",
    "            if as_np_array:\n",
    "                corpus[l_pair][file_name] = np.array(file.read().split('\\n'), dtype=object)\n",
    "            else:\n",
    "                corpus[l_pair][file_name[:3]] = file.read().split('\\n')\n",
    "            file.close()\n",
    "            remove(path)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_corpus(output_data_dir, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete empty lines and lines with xml tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2048549\n2048549\n1957802\n1957802\n2007131\n2007131\n"
    }
   ],
   "source": [
    "for pair, l_data in corpus.items():\n",
    "\n",
    "    # Find special lines\n",
    "    empty_lines = np.array([], dtype=int)\n",
    "    for _, value in l_data.items():\n",
    "        is_empty = np.vectorize(lambda x: len(x) == 0 or x[0] == \"<\")\n",
    "        indices = np.nonzero(is_empty(value))[0]\n",
    "        empty_lines = np.concatenate((empty_lines, indices))\n",
    "    empty_lines = np.unique(empty_lines)\n",
    "\n",
    "    # Remove lines with an xml tag or an empty char\n",
    "    for key, value in l_data.items():\n",
    "        new_corpus = np.delete(value, empty_lines)\n",
    "        corpus[pair][key] = new_corpus.tolist()\n",
    "        print(len(new_corpus))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang_pair, pair_dict in corpus.items():\n",
    "    for file_name, data in pair_dict.items():\n",
    "        file = open(join_path(output_data_dir, file_name), 'w')\n",
    "        file.write(\"\\n\".join(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following steps must be run after executing the multialign script and the BPE tokenization script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join language files and add translation token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dir = './data/tokenized/'\n",
    "output_dir = './data/'\n",
    "\n",
    "for sub_set in listdir(tokenized_dir):\n",
    "    sub_set_path = join_path(tokenized_dir, sub_set)\n",
    "\n",
    "    corpus = {}\n",
    "    src_data = []\n",
    "    tgt_data = []\n",
    "\n",
    "    for file_name in listdir(sub_set_path):\n",
    "        file_path = join_path(sub_set_path, file_name)\n",
    "        file = open(file_path, 'r')\n",
    "        corpus[file_name[:-4]] = file.read().split('\\n')\n",
    "\n",
    "    # An extra line will be created when loading the data to memory,\n",
    "    # that's why the -1 is there\n",
    "    for i in range(0, len(corpus['en']) - 1):\n",
    "        for src in corpus:\n",
    "            targets = filter(lambda x: x != src, corpus.keys())\n",
    "            for tgt in targets:\n",
    "                src_sentence = '_src_{}_tgt_{} '.format(src, tgt) + corpus[src][i]\n",
    "                src_data.append(src_sentence)\n",
    "                tgt_data.append(corpus[tgt][i])\n",
    "\n",
    "    out_src = open(join_path(output_dir, 'europarl_{}_src.txt'.format(sub_set)), 'w')\n",
    "    out_src.write(\"\\n\".join(src_data))\n",
    "    out_src = open(join_path(output_dir, 'europarl_{}_tgt.txt'.format(sub_set)), 'w')\n",
    "    out_src.write(\"\\n\".join(tgt_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing classifier data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Back-Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = './data/translated/'\n",
    "back_translation_num = 3\n",
    "lang_pool = ['en', 'es', 'fr', 'de']\n",
    "ignore = ['de_en', 'es_fr', 'fr_de', 'fr_en', 'fr_es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting loops for: de_es.txt\nElapsed time to generate T0 for es to en: 84.76807451248169s\nElapsed time to generate Back0 for en to es: 82.66909098625183s\nElapsed time to generate T1 for es to en: 77.02899098396301s\nElapsed time to generate Back1 for en to es: 80.14960050582886s\nElapsed time to generate T2 for es to en: 75.55847644805908s\nElapsed time to generate Back2 for en to es: 79.01752805709839s\nElapsed time to generate T3 for es to en: 74.84669542312622s\nElapsed time to generate T0 for es to fr: 98.60221600532532s\nElapsed time to generate Back0 for fr to es: 82.73007440567017s\nElapsed time to generate T1 for es to fr: 87.15043616294861s\nElapsed time to generate Back1 for fr to es: 79.43580174446106s\nElapsed time to generate T2 for es to fr: 85.46473169326782s\nElapsed time to generate Back2 for fr to es: 78.61906862258911s\nElapsed time to generate T3 for es to fr: 85.17634749412537s\nElapsed time to generate T0 for es to de: 88.93029475212097s\nElapsed time to generate Back0 for de to es: 84.67667698860168s\nElapsed time to generate T1 for es to de: 80.30507731437683s\nElapsed time to generate Back1 for de to es: 79.98386096954346s\nElapsed time to generate T2 for es to de: 77.5165650844574s\nElapsed time to generate Back2 for de to es: 79.51469588279724s\nElapsed time to generate T3 for es to de: 76.8915913105011s\nStarting loops for: es_en.txt\nElapsed time to generate T0 for en to es: 92.83233094215393s\nElapsed time to generate Back0 for es to en: 82.07849621772766s\nElapsed time to generate T1 for en to es: 83.01856255531311s\nElapsed time to generate Back1 for es to en: 78.1855297088623s\nElapsed time to generate T2 for en to es: 81.0507447719574s\nElapsed time to generate Back2 for es to en: 77.63896560668945s\nElapsed time to generate T3 for en to es: 80.85524415969849s\nElapsed time to generate T0 for en to fr: 101.6391441822052s\nElapsed time to generate Back0 for fr to en: 80.88096356391907s\nElapsed time to generate T1 for en to fr: 88.74029016494751s\nElapsed time to generate Back1 for fr to en: 77.2154974937439s\nElapsed time to generate T2 for en to fr: 86.77728772163391s\nElapsed time to generate Back2 for fr to en: 75.8175630569458s\nElapsed time to generate T3 for en to fr: 87.56125497817993s\nElapsed time to generate T0 for en to de: 90.73789358139038s\nElapsed time to generate Back0 for de to en: 80.65399765968323s\nElapsed time to generate T1 for en to de: 79.5317153930664s\nElapsed time to generate Back1 for de to en: 75.78821921348572s\nElapsed time to generate T2 for en to de: 77.46282196044922s\nElapsed time to generate Back2 for de to en: 74.40764164924622s\nElapsed time to generate T3 for en to de: 76.47659659385681s\nStarting loops for: en_es.txt\nElapsed time to generate T0 for es to en: 87.88759565353394s\nElapsed time to generate Back0 for en to es: 85.7509036064148s\nElapsed time to generate T1 for es to en: 79.78813028335571s\nElapsed time to generate Back1 for en to es: 81.96003675460815s\nElapsed time to generate T2 for es to en: 76.89145827293396s\nElapsed time to generate Back2 for en to es: 82.01227712631226s\nElapsed time to generate T3 for es to en: 77.2000184059143s\nElapsed time to generate T0 for es to fr: 100.50489115715027s\nElapsed time to generate Back0 for fr to es: 84.73199796676636s\nElapsed time to generate T1 for es to fr: 89.39616966247559s\nElapsed time to generate Back1 for fr to es: 80.92732191085815s\nElapsed time to generate T2 for es to fr: 87.1550965309143s\nElapsed time to generate Back2 for fr to es: 79.72788500785828s\nElapsed time to generate T3 for es to fr: 86.17291855812073s\nElapsed time to generate T0 for es to de: 90.76012921333313s\nElapsed time to generate Back0 for de to es: 84.64992165565491s\nElapsed time to generate T1 for es to de: 80.58884716033936s\nElapsed time to generate Back1 for de to es: 81.3039243221283s\nElapsed time to generate T2 for es to de: 78.3812325000763s\nElapsed time to generate Back2 for de to es: 80.00719261169434s\nElapsed time to generate T3 for es to de: 78.55789160728455s\nStarting loops for: es_de.txt\nElapsed time to generate T0 for de to en: 86.37652516365051s\nElapsed time to generate Back0 for en to de: 81.30768513679504s\nElapsed time to generate T1 for de to en: 77.58126831054688s\nElapsed time to generate Back1 for en to de: 79.14741039276123s\nElapsed time to generate T2 for de to en: 77.08084106445312s\nElapsed time to generate Back2 for en to de: 78.32942914962769s\nElapsed time to generate T3 for de to en: 76.13157963752747s\nElapsed time to generate T0 for de to es: 91.05463433265686s\nElapsed time to generate Back0 for es to de: 82.19389057159424s\nElapsed time to generate T1 for de to es: 80.42874956130981s\nElapsed time to generate Back1 for es to de: 78.93860173225403s\nElapsed time to generate T2 for de to es: 77.7663631439209s\nElapsed time to generate Back2 for es to de: 76.54196310043335s\nElapsed time to generate T3 for de to es: 77.30394101142883s\nElapsed time to generate T0 for de to fr: 100.71157336235046s\nElapsed time to generate Back0 for fr to de: 83.34672045707703s\nElapsed time to generate T1 for de to fr: 87.04145193099976s\nElapsed time to generate Back1 for fr to de: 77.63479256629944s\nElapsed time to generate T2 for de to fr: 83.55938196182251s\nElapsed time to generate Back2 for fr to de: 75.47313928604126s\nElapsed time to generate T3 for de to fr: 83.77993869781494s\nStarting loops for: en_de.txt\nElapsed time to generate T0 for de to en: 86.5259096622467s\nElapsed time to generate Back0 for en to de: 83.98984932899475s\nElapsed time to generate T1 for de to en: 78.98085021972656s\nElapsed time to generate Back1 for en to de: 79.15959620475769s\nElapsed time to generate T2 for de to en: 76.5737087726593s\nElapsed time to generate Back2 for en to de: 78.31491327285767s\nElapsed time to generate T3 for de to en: 75.24990272521973s\nElapsed time to generate T0 for de to es: 90.4669120311737s\nElapsed time to generate Back0 for es to de: 81.49372720718384s\nElapsed time to generate T1 for de to es: 80.26681756973267s\nElapsed time to generate Back1 for es to de: 78.40799283981323s\nElapsed time to generate T2 for de to es: 80.21294593811035s\nElapsed time to generate Back2 for es to de: 78.55602979660034s\nElapsed time to generate T3 for de to es: 78.80881214141846s\nElapsed time to generate T0 for de to fr: 100.64365839958191s\nElapsed time to generate Back0 for fr to de: 83.05326318740845s\nElapsed time to generate T1 for de to fr: 86.81759667396545s\nElapsed time to generate Back1 for fr to de: 76.95543479919434s\nElapsed time to generate T2 for de to fr: 83.9619779586792s\nElapsed time to generate Back2 for fr to de: 75.5181713104248s\nElapsed time to generate T3 for de to fr: 83.3027720451355s\nStarting loops for: de_fr.txt\nElapsed time to generate T0 for fr to en: 86.65200614929199s\nElapsed time to generate Back0 for en to fr: 91.13272047042847s\nElapsed time to generate T1 for fr to en: 76.80081987380981s\nElapsed time to generate Back1 for en to fr: 86.63041043281555s\nElapsed time to generate T2 for fr to en: 76.5078604221344s\nElapsed time to generate Back2 for en to fr: 88.32354784011841s\nElapsed time to generate T3 for fr to en: 77.2485556602478s\nElapsed time to generate T0 for fr to es: 89.6854817867279s\nElapsed time to generate Back0 for es to fr: 90.45636677742004s\nElapsed time to generate T1 for fr to es: 81.37067556381226s\nElapsed time to generate Back1 for es to fr: 86.08953070640564s\nElapsed time to generate T2 for fr to es: 79.38331770896912s\nElapsed time to generate Back2 for es to fr: 85.19572401046753s\nElapsed time to generate T3 for fr to es: 78.521475315094s\nElapsed time to generate T0 for fr to de: 88.55502843856812s\nElapsed time to generate Back0 for de to fr: 90.56639504432678s\nElapsed time to generate T1 for fr to de: 78.46335458755493s\nElapsed time to generate Back1 for de to fr: 86.78244042396545s\nElapsed time to generate T2 for fr to de: 76.34075140953064s\nElapsed time to generate Back2 for de to fr: 84.00892281532288s\nElapsed time to generate T3 for fr to de: 76.29793930053711s\nStarting loops for: en_fr.txt\nElapsed time to generate T0 for fr to en: 88.89407515525818s\nElapsed time to generate Back0 for en to fr: 93.18848896026611s\nElapsed time to generate T1 for fr to en: 77.95740032196045s\nElapsed time to generate Back1 for en to fr: 87.76012873649597s\nElapsed time to generate T2 for fr to en: 75.41681456565857s\nElapsed time to generate Back2 for en to fr: 86.32724976539612s\nElapsed time to generate T3 for fr to en: 76.62402439117432s\nElapsed time to generate T0 for fr to es: 92.18642568588257s\nElapsed time to generate Back0 for es to fr: 91.72026205062866s\nElapsed time to generate T1 for fr to es: 82.07870626449585s\nElapsed time to generate Back1 for es to fr: 87.40587902069092s\nElapsed time to generate T2 for fr to es: 80.49156737327576s\nElapsed time to generate Back2 for es to fr: 86.32513856887817s\nElapsed time to generate T3 for fr to es: 79.30003929138184s\nElapsed time to generate T0 for fr to de: 90.02225947380066s\nElapsed time to generate Back0 for de to fr: 90.75959396362305s\nElapsed time to generate T1 for fr to de: 79.8047993183136s\nElapsed time to generate Back1 for de to fr: 87.57026100158691s\nElapsed time to generate T2 for fr to de: 78.4607629776001s\nElapsed time to generate Back2 for de to fr: 85.45860815048218s\nElapsed time to generate T3 for fr to de: 77.347825050354s\n"
    }
   ],
   "source": [
    "def translate_text(text, src, tgt, file_name, dir_path):\n",
    "    start = time.time()\n",
    "    response = requests.post('http://localhost:8080/translate', data = {'text': text, 'src': src, 'tgt': tgt})\n",
    "    end = time.time()\n",
    "    print('Elapsed time to generate {} for {} to {}: {}s'.format(file_name, src, tgt, end - start))\n",
    "    res_file = open(join_path(dir_path, '{}.txt'.format(file_name)), 'w')\n",
    "    res_file.write(response.text)\n",
    "    return response.text\n",
    "\n",
    "for file_name in listdir(location):\n",
    "    path = join_path(location, file_name)\n",
    "    dir_path = path[:-4]\n",
    "    if os.path.isfile(path) and file_name[:-4] not in ignore:\n",
    "        print(\"Starting loops for:\", file_name)\n",
    "        original_lang = file_name[:2]\n",
    "        translated_lang = file_name[-6:-4]\n",
    "\n",
    "        if not os.path.isdir(dir_path):\n",
    "            mkdir(dir_path)\n",
    "\n",
    "        content = open(path, 'r').read()\n",
    "        \n",
    "        for tgt in filter(lambda x: x != translated_lang, lang_pool):\n",
    "            tgt_dir = join_path(dir_path, tgt)\n",
    "            if not os.path.isdir(tgt_dir):\n",
    "                mkdir(tgt_dir)\n",
    "\n",
    "            last_back = content\n",
    "            for i in range(0, back_translation_num):\n",
    "                translation = translate_text(last_back, translated_lang, tgt, 'T{}'.format(i), tgt_dir)\n",
    "                last_back = translate_text(translation, tgt, translated_lang, 'Back{}'.format(i), tgt_dir)\n",
    "            translate_text(last_back, translated_lang, tgt, 'T{}'.format(back_translation_num), tgt_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate BLEU-Score Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597247013791",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}